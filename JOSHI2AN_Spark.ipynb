{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m6cjbEpFxxLn"
      },
      "outputs": [],
      "source": [
        "# Name: ANAY ABHIJIT JOSHI\n",
        "# Date: 30 OCTOBER 2024\n",
        "\n",
        "# PROJECT 4: Big Data with PySpark using Anaconda & Jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PySpark is now available in pypi. To install, I will just run pip install pyspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NXWsJEUx0_k",
        "outputId": "805fe236-6a90-43c7-a906-db7e65610fdc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Beautiful Soup is a Python package for parsing HTML and XML documents, including those with malformed markup.\n",
        "!pip install requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3j1yzdLx6T5",
        "outputId": "e375027c-5251-49e2-e8d4-3a3c90d6acbf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here are the required Python modules and libraries to be imported for QUESTION 2\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Base URL for NCEI Bulk Data Download\n",
        "base_url = \"https://www.ncei.noaa.gov/data/global-summary-of-the-day/access\"\n",
        "\n",
        "# Local directory to store the downloaded files of Cincinnati and Florida\n",
        "data_directory = \"./weather_data\"\n",
        "\n",
        "# Create the directory if it does not exist in the current working directory\n",
        "if not os.path.exists(data_directory):\n",
        "    # Create the directory now\n",
        "    os.makedirs(data_directory)\n",
        "\n",
        "# Here, I am downloading the weather data for Cincinnati and Florida for the years 2015 to 2024\n",
        "years = range(2015, 2025)   # Last year is exclusive\n",
        "# Stations for Cincinnati and Florida, respectively\n",
        "stations = [\"72429793812\", \"99495199999\"]\n",
        "\n",
        "# Now, let's download the weather data for Cincinnati and Florida for the years 2015 to 2024\n",
        "def download_file(url, local_filename):\n",
        "    # Download the file from the URL\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        # Check if the request was successful, i.e., HTTP status code of '200'\n",
        "        if r.status_code == 200:\n",
        "            # Save the downloaded file to the local directory\n",
        "            with open(local_filename, 'wb') as f:\n",
        "                # Iterate over the content of the response\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    # Write the content to the file\n",
        "                    f.write(chunk)\n",
        "            # Now, let's print the local filename to check the downloaded file's sta\n",
        "            print(f\"Successfully Downloaded: {local_filename} !\")\n",
        "        # If the request was not successful\n",
        "        else:\n",
        "            print(f\"Error! Failed to download: {url}\")\n",
        "\n",
        "# Now, let's download the weather data for Cincinnati and Florida for the years 2015 to 2024, via a loop (for)\n",
        "for year in years:\n",
        "    # Construct the URL for the year\n",
        "    year_url = f\"{base_url}/{year}/\"\n",
        "\n",
        "    # Now, let's get the response from the URL\n",
        "    response = requests.get(year_url)\n",
        "    # Again, check if the response was successful, i.e., HTTP status code of '200'\n",
        "    if response.status_code != 200:\n",
        "        # Print the error message\n",
        "        print(f\"Error! Failed to access: {year_url}\")\n",
        "        # Now, skip to the next iteration\n",
        "        continue\n",
        "\n",
        "    # Parse the HTML content of the response using the 'BeautifulSoup' library\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Find all the links in the HTML content on the page\n",
        "    links = soup.find_all('a')\n",
        "\n",
        "    # Now, let's download the weather data for Cincinnati and Florida for the specific year\n",
        "    for station in stations:\n",
        "        # Construct the filename\n",
        "        filename = f\"{station}.csv\"\n",
        "        # Iterate over the links\n",
        "        for link in links:\n",
        "            # Check if the link's 'href' attribute matches the filename\n",
        "            if link.get('href') == filename:\n",
        "                # Construct the URL for the file\n",
        "                file_url = f\"{year_url}{filename}\"\n",
        "                # Construct the local path for the file\n",
        "                local_path = os.path.join(data_directory, f\"{year}_{filename}\")\n",
        "                # Download the file\n",
        "                download_file(file_url, local_path)\n",
        "                # Finally, break the loop\n",
        "                break\n",
        "\n",
        "# Now, let's check the number of rows in each dataset\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Weather Data Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# List to store the counts of the datasets. Initially, it is empty because I have not counted the rows yet\n",
        "dataset_counts = []\n",
        "print(f\" \")\n",
        "\n",
        "# Now, let's count the number of rows in each dataset\n",
        "for year in years:\n",
        "    # Iterate over the stations\n",
        "    for station in stations:\n",
        "        # Skip the year 2016 for the station \"99495199999\" because weather data for Florida (station #99495199999) does not exist for the year 2016\n",
        "        if year == 2016 and station == \"99495199999\":\n",
        "            # Skip to the next iteration\n",
        "            continue\n",
        "\n",
        "        # Construct the file path again\n",
        "        file_path = os.path.join(data_directory, f\"{year}_{station}.csv\")\n",
        "\n",
        "        # Check if the file exists already\n",
        "        if os.path.exists(file_path):\n",
        "            # Read the CSV file using Spark\n",
        "            df = spark.read.option(\"header\", \"true\").csv(file_path)\n",
        "            # Count the total number of rows in one of the given datasets\n",
        "            row_count = df.count()\n",
        "\n",
        "            # Append the year, station, and row count to the list\n",
        "            dataset_counts.append((year, station, row_count))\n",
        "            # Cincinnati Station\n",
        "            if station == \"72429793812\":\n",
        "                # Print the year, station, and row count\n",
        "                print(f\"Cincinnati --> Year: {year}, Station: {station}, Count: {row_count}\")\n",
        "            # Florida Station\n",
        "            elif station == \"99495199999\":\n",
        "                # Print the year, station, and row count\n",
        "                print(f\"Florida    --> Year: {year}, Station: {station}, Count: {row_count}\")\n",
        "        # If the file does not exist\n",
        "        else:\n",
        "            print(f\"Error! File not found for Year: {year}, Station: {station}\")\n",
        "\n",
        "# Now, let's stop the Spark session and see the total number of results\n",
        "if len(dataset_counts) == 19:\n",
        "    print(\"\\nTotal Results: 19 (as expected)\")\n",
        "else:\n",
        "    print(f\"\\nTotal Results: {len(dataset_counts)} (unexpected)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj7fZF7FyN0E",
        "outputId": "d61cc978-fedf-4303-cc35-9ed811bedb19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully Downloaded: ./weather_data/2015_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2015_99495199999.csv !\n",
            "Successfully Downloaded: ./weather_data/2016_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2017_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2017_99495199999.csv !\n",
            "Successfully Downloaded: ./weather_data/2018_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2018_99495199999.csv !\n",
            "Successfully Downloaded: ./weather_data/2019_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2019_99495199999.csv !\n",
            "Successfully Downloaded: ./weather_data/2020_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2020_99495199999.csv !\n",
            "Successfully Downloaded: ./weather_data/2021_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2021_99495199999.csv !\n",
            "Successfully Downloaded: ./weather_data/2022_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2022_99495199999.csv !\n",
            "Successfully Downloaded: ./weather_data/2023_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2023_99495199999.csv !\n",
            "Successfully Downloaded: ./weather_data/2024_72429793812.csv !\n",
            "Successfully Downloaded: ./weather_data/2024_99495199999.csv !\n",
            " \n",
            "Cincinnati --> Year: 2015, Station: 72429793812, Count: 365\n",
            "Florida    --> Year: 2015, Station: 99495199999, Count: 355\n",
            "Cincinnati --> Year: 2016, Station: 72429793812, Count: 366\n",
            "Cincinnati --> Year: 2017, Station: 72429793812, Count: 365\n",
            "Florida    --> Year: 2017, Station: 99495199999, Count: 283\n",
            "Cincinnati --> Year: 2018, Station: 72429793812, Count: 365\n",
            "Florida    --> Year: 2018, Station: 99495199999, Count: 363\n",
            "Cincinnati --> Year: 2019, Station: 72429793812, Count: 365\n",
            "Florida    --> Year: 2019, Station: 99495199999, Count: 345\n",
            "Cincinnati --> Year: 2020, Station: 72429793812, Count: 366\n",
            "Florida    --> Year: 2020, Station: 99495199999, Count: 365\n",
            "Cincinnati --> Year: 2021, Station: 72429793812, Count: 365\n",
            "Florida    --> Year: 2021, Station: 99495199999, Count: 104\n",
            "Cincinnati --> Year: 2022, Station: 72429793812, Count: 365\n",
            "Florida    --> Year: 2022, Station: 99495199999, Count: 259\n",
            "Cincinnati --> Year: 2023, Station: 72429793812, Count: 365\n",
            "Florida    --> Year: 2023, Station: 99495199999, Count: 276\n",
            "Cincinnati --> Year: 2024, Station: 72429793812, Count: 301\n",
            "Florida    --> Year: 2024, Station: 99495199999, Count: 133\n",
            "\n",
            "Total Results: 19 (as expected)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here are some more more Python modules and libraries to be imported\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit, mean, stddev, count, when, expr, max as spark_max, min as spark_min, year, month\n",
        "\n",
        "# Let's create a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Weather Data Analysis\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Now, let's load the data into DataFrames\n",
        "data_directory = \"./weather_data\"\n",
        "\n",
        "# Load CSV files into DataFrames for Cincinnati and Florida\n",
        "cincinnati_files = [f\"{data_directory}/{year}_72429793812.csv\" for year in years]\n",
        "# As I stated earlier, weather data for Florida (station #99495199999) does not exist for the year 2016\n",
        "florida_files = [f\"{data_directory}/{year}_99495199999.csv\" for year in years if year != 2016]\n",
        "\n",
        "# Read the data from the CSV files\n",
        "cincinnati_df = spark.read.option(\"header\", \"true\").csv(cincinnati_files)\n",
        "florida_df = spark.read.option(\"header\", \"true\").csv(florida_files)\n",
        "\n",
        "# Display the total number of row counts\n",
        "print(f\"Cincinnati Data Count (Total Number of Rows): {cincinnati_df.count()}\")\n",
        "print(f\"Florida Data Count (Total Number of Rows)   : {florida_df.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frVLz2iOzmrA",
        "outputId": "cac1a05b-a067-41c3-ec67-7821dda81c28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cincinnati Data Count (Total Number of Rows): 3588\n",
            "Florida Data Count (Total Number of Rows)   : 2483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 3\n",
        "# Find the hottest day (column MAX) for each year:\n",
        "# Provide the corresponding station code, station name, date, and temperature (columns: STATION, NAME, DATE, MAX).\n",
        "# There should be 10 results.\n",
        "\n",
        "# NOTE: Ignoring all the Missing Values of 9999.9 for fetching the accurate data\n",
        "\n",
        "# Now, let's find the hottest day (column MAX) for each year in Cincinnati and Florida - excluding the year 2016 for Florida\n",
        "\n",
        "# Import required modules and libraries of Python\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import col, max as spark_max, lit\n",
        "\n",
        "# List to store the hottest days, initially, it would be empty\n",
        "hottest_days = []\n",
        "\n",
        "# Iterating over the years and stations, defined earlier, via a \"for\" loop\n",
        "for year in years:\n",
        "    for station in stations:\n",
        "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
        "\n",
        "        # Check if the file exists\n",
        "        if os.path.exists(file_path):\n",
        "            df = spark.read.option(\"header\", \"true\").csv(file_path)\n",
        "\n",
        "            # Remove rows with 9999.9 values and find the maximum temperature\n",
        "            valid_df = df.filter(col(\"MAX\") != 9999.9)\n",
        "            max_temp = valid_df.agg(spark_max(\"MAX\").alias(\"Max_Temp\")).collect()[0][\"Max_Temp\"]\n",
        "\n",
        "            # If the max temperature is still 9999.9 after filtering, use the second-highest value\n",
        "            hottest_day = valid_df.filter(col(\"MAX\") == max_temp) \\\n",
        "                                  .select(\"STATION\", \"NAME\", \"DATE\", \"MAX\") \\\n",
        "                                  .withColumn(\"YEAR\", lit(year)) \\\n",
        "                                  .collect()[0]\n",
        "\n",
        "            # Append the hottest day to the list now\n",
        "            hottest_days.append(Row(YEAR=year, STATION=hottest_day[\"STATION\"], NAME=hottest_day[\"NAME\"], DATE=hottest_day[\"DATE\"], MAX=hottest_day[\"MAX\"]))\n",
        "\n",
        "# Create a DataFrame from the list of hottest days for each year\n",
        "hottest_days_df = spark.createDataFrame(hottest_days)\n",
        "\n",
        "# Finally, let's display the hottest days for each year in Cincinnati and Florida (10 for Cincinnati and 9 for Florida)\n",
        "hottest_days_df = hottest_days_df.orderBy(\"YEAR\")\n",
        "\n",
        "# Group the hottest days by year\n",
        "grouped_years = hottest_days_df.collect()\n",
        "\n",
        "# Print the hottest days by year\n",
        "print(\"Hottest Days by Year (Cincinnati and Florida):\\n\")\n",
        "print(f\" Year  |    Station   |                 Station Name                       |    Date      | Maximum Temperature\")\n",
        "print(f\"-------|--------------|----------------------------------------------------|--------------|---------------------\")\n",
        "\n",
        "# Iterating over the grouped years for the final time\n",
        "last_year = None\n",
        "for row in grouped_years:\n",
        "    if last_year and row['YEAR'] != last_year:\n",
        "        print(\"\\n\")  # Extra line for readability\n",
        "    print(f\"{row['YEAR']:^6} | {row['STATION']:^12} | {row['NAME']:<50} | {row['DATE']:^12} | {float(row['MAX']):>7.1f}\")\n",
        "    last_year = row['YEAR']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmoTNck1zutw",
        "outputId": "ff8f6d09-142e-49a9-cceb-2414a23fdc45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hottest Days by Year (Cincinnati and Florida):\n",
            "\n",
            " Year  |    Station   |                 Station Name                       |    Date      | Maximum Temperature\n",
            "-------|--------------|----------------------------------------------------|--------------|---------------------\n",
            " 2015  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2015-06-12  |    91.9\n",
            " 2015  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2015-07-28  |    90.0\n",
            "\n",
            "\n",
            " 2016  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2016-07-24  |    93.9\n",
            "\n",
            "\n",
            " 2017  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2017-07-22  |    91.9\n",
            " 2017  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2017-05-13  |    88.3\n",
            "\n",
            "\n",
            " 2018  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2018-07-04  |    96.1\n",
            " 2018  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2018-09-15  |    90.1\n",
            "\n",
            "\n",
            " 2019  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2019-09-30  |    95.0\n",
            " 2019  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2019-09-06  |    91.6\n",
            "\n",
            "\n",
            " 2020  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2020-07-05  |    93.9\n",
            " 2020  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2020-04-13  |    91.8\n",
            "\n",
            "\n",
            " 2021  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2021-08-12  |    95.0\n",
            " 2021  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2021-04-18  |    86.2\n",
            "\n",
            "\n",
            " 2022  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2022-06-14  |    96.1\n",
            " 2022  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2022-05-06  |    89.6\n",
            "\n",
            "\n",
            " 2023  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2023-08-23  |    96.1\n",
            " 2023  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2023-07-09  |    90.9\n",
            "\n",
            "\n",
            " 2024  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2024-08-30  |   100.9\n",
            " 2024  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2024-05-14  |    86.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 4:\n",
        "  # Find the coldest day (column MIN) for the month of March across all years (2015-2024) (Points: 1):\n",
        "  # Provide the corresponding station code, station name, date, and temperature (columns: STATION, NAME, DATE, MIN).\n",
        "  # There should be 1 result.\n",
        "\n",
        "# Here is an empty list to store the coldest days in March\n",
        "march_min_temps = []\n",
        "\n",
        "# Iterate over the years and stations\n",
        "for year in years:\n",
        "    # Iterate over the stations\n",
        "    for station in stations:\n",
        "        # Now, here is the file path to each CSV file for reading the data\n",
        "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
        "\n",
        "        # Check if the file exists\n",
        "        if os.path.exists(file_path):\n",
        "            # Read the CSV file using Spark\n",
        "            df = spark.read.option(\"header\", \"true\").csv(file_path)\n",
        "\n",
        "            # Filter the data for the month of March\n",
        "            march_df = df.filter(month(col(\"DATE\")) == 3)\n",
        "            min_temp = march_df.agg(spark_min(\"MIN\").alias(\"Min_Temp\")).collect()[0][\"Min_Temp\"]\n",
        "\n",
        "            # If the minimum temperature is not None then, find the coldest day\n",
        "            if min_temp is not None:\n",
        "                # Coldest day for the month of March\n",
        "                coldest_day = march_df.filter(col(\"MIN\") == min_temp) \\\n",
        "                                      .select(\"STATION\", \"NAME\", \"DATE\", \"MIN\") \\\n",
        "                                      .withColumn(\"YEAR\", lit(year)) \\\n",
        "                                      .collect()[0]\n",
        "                # Append the coldest day to the list\n",
        "                march_min_temps.append(coldest_day)\n",
        "\n",
        "# Create a DataFrame from the list of coldest days in March\n",
        "march_min_temps_df = spark.createDataFrame(march_min_temps)\n",
        "# Finally, find that one coldest day in March across all years (2015-2024)\n",
        "coldest_march_day = march_min_temps_df.orderBy(\"MIN\").limit(1).collect()[0]\n",
        "\n",
        "# Display the result in table format for better visualization and readability\n",
        "print(\"\\nOne Coldest Day in March (2015-2024) from Cincinnati and Florida (both):\\n\")\n",
        "print(f\" Year  |    Station   |                 Station Name                       |    Date      | Minimum Temperature\")\n",
        "print(f\"-------|--------------|----------------------------------------------------|--------------|---------------------\")\n",
        "print(f\"{coldest_march_day['YEAR']:^6} | {coldest_march_day['STATION']:^12} | {coldest_march_day['NAME']:<50} | {coldest_march_day['DATE']:^12} | {float(coldest_march_day['MIN']):>7.1f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo10GUEm8a4-",
        "outputId": "dcfa9243-7eed-4bc0-e860-bcdf9ca5f4b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "One Coldest Day in March (2015-2024) from Cincinnati and Florida (both):\n",
            "\n",
            " Year  |    Station   |                 Station Name                       |    Date      | Minimum Temperature\n",
            "-------|--------------|----------------------------------------------------|--------------|---------------------\n",
            " 2015  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2015-03-06  |     3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 4 (continued) -\n",
        "# Here is an empty list to store the coldest days in March as a dictionary for each station (Cincinnati and Florida)\n",
        "march_min_temps = {\"72429793812\": [], \"99495199999\": []}\n",
        "\n",
        "# Iterate over the years and stations\n",
        "for year in years:\n",
        "    # Iterate over the stations\n",
        "    for station in stations:\n",
        "        # Now, construct the file path to each CSV file for reading the data\n",
        "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
        "\n",
        "        # Finally, check if the file exists\n",
        "        if os.path.exists(file_path):\n",
        "            # Let's read the CSV file using Spark\n",
        "            df = spark.read.option(\"header\", \"true\").csv(file_path)\n",
        "\n",
        "            # Now, filter the data for the month of March, as per the requirement\n",
        "            march_df = df.filter(month(col(\"DATE\")) == 3)\n",
        "            # Find the minimum temperature for the month of March\n",
        "            min_temp = march_df.agg(spark_min(\"MIN\").alias(\"Min_Temp\")).collect()[0][\"Min_Temp\"]\n",
        "\n",
        "            # If the minimum temperature is not None, then, find the coldest day\n",
        "            if min_temp is not None:\n",
        "                # Find the coldest day for the month of March\n",
        "                coldest_day = march_df.filter(col(\"MIN\") == min_temp) \\\n",
        "                                      .select(\"STATION\", \"NAME\", \"DATE\", \"MIN\") \\\n",
        "                                      .withColumn(\"YEAR\", lit(year)) \\\n",
        "                                      .collect()[0]\n",
        "\n",
        "                # Now, append the coldest day to the list\n",
        "                march_min_temps[station].append(coldest_day)\n",
        "\n",
        "# Convert the list of coldest days to DataFrames for Cincinnati and Florida each\n",
        "cincinnati_min_df = spark.createDataFrame(march_min_temps[\"72429793812\"]).orderBy(\"MIN\").limit(1)\n",
        "florida_min_df = spark.createDataFrame(march_min_temps[\"99495199999\"]).orderBy(\"MIN\").limit(1)\n",
        "\n",
        "# Collect the results from the DataFrames\n",
        "coldest_cincinnati_day = cincinnati_min_df.collect()[0]\n",
        "coldest_florida_day = florida_min_df.collect()[0]\n",
        "\n",
        "# Display the result in table format for better readability and visualization\n",
        "print(\"\\nColdest Day in March (2015-2024) for Cincinnati and Florida (each):\\n\")\n",
        "print(f\" Year  |    Station   |                 Station Name                       |    Date      | Minimum Temperature\")\n",
        "print(f\"-------|--------------|----------------------------------------------------|--------------|---------------------\")\n",
        "print(f\"{coldest_cincinnati_day['YEAR']:^6} | {coldest_cincinnati_day['STATION']:^12} | {coldest_cincinnati_day['NAME']:<50} | {coldest_cincinnati_day['DATE']:^12} | {float(coldest_cincinnati_day['MIN']):>7.1f}\")\n",
        "print(f\"{coldest_florida_day['YEAR']:^6} | {coldest_florida_day['STATION']:^12} | {coldest_florida_day['NAME']:<50} | {coldest_florida_day['DATE']:^12} | {float(coldest_florida_day['MIN']):>7.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk8IZMk4_Rcl",
        "outputId": "44c39bf4-7f5b-4f88-9a10-4c031ccfaf22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coldest Day in March (2015-2024) for Cincinnati and Florida (each):\n",
            "\n",
            " Year  |    Station   |                 Station Name                       |    Date      | Minimum Temperature\n",
            "-------|--------------|----------------------------------------------------|--------------|---------------------\n",
            " 2015  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2015-03-06  |     3.2\n",
            " 2022  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2022-03-13  |    45.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 5:\n",
        "# Find the year with the most precipitation for Cincinnati and Florida (Points: 1):\n",
        "# Provide the corresponding station code, station name, and year (columns: STATION, NAME, YEAR, Mean of PRCP).\n",
        "# There should be 2 results.\n",
        "\n",
        "# Again, necessary imports\n",
        "from pyspark.sql.functions import year, col, mean\n",
        "\n",
        "# Again, load the data into DataFrames from the CSV files for Cincinnati\n",
        "cincinnati_files = [f\"{data_directory}/{year}_72429793812.csv\" for year in years]\n",
        "cincinnati_df = spark.read.option(\"header\", \"true\").csv(cincinnati_files)\n",
        "\n",
        "# Calculate mean precipitation by year for Cincinnati only\n",
        "cincinnati_precip = cincinnati_df.withColumn(\"YEAR\", year(col(\"DATE\"))) \\\n",
        "    .groupBy(\"YEAR\", \"STATION\", \"NAME\") \\\n",
        "    .agg(mean(\"PRCP\").alias(\"Mean_PRCP\")) \\\n",
        "    .orderBy(col(\"Mean_PRCP\").desc()) \\\n",
        "    .limit(1)\n",
        "\n",
        "# Now, load the data into DataFrames from the CSV files for Florida\n",
        "florida_files = [f\"{data_directory}/{year}_99495199999.csv\" for year in years if year != 2016]\n",
        "florida_df = spark.read.option(\"header\", \"true\").csv(florida_files)\n",
        "\n",
        "# Calculate mean precipitation by year for Florida only\n",
        "florida_precip = florida_df.withColumn(\"YEAR\", year(col(\"DATE\"))) \\\n",
        "    .groupBy(\"YEAR\", \"STATION\", \"NAME\") \\\n",
        "    .agg(mean(\"PRCP\").alias(\"Mean_PRCP\")) \\\n",
        "    .orderBy(col(\"Mean_PRCP\").desc()) \\\n",
        "    .limit(1)\n",
        "\n",
        "# Collect results from the DataFrames for both Cincinnati and Florida\n",
        "cincinnati_result = cincinnati_precip.collect()[0]\n",
        "florida_result = florida_precip.collect()[0]\n",
        "\n",
        "# Display the result in table format for better readability and visualization\n",
        "print(\"\\nYear with Most Precipitation for Cincinnati and Florida:\\n\")\n",
        "print(f\" Year  |    Station   |                 Station Name                       | Mean PRCP\")\n",
        "print(f\"-------|--------------|----------------------------------------------------|----------\")\n",
        "print(f\"{cincinnati_result['YEAR']:^6} | {cincinnati_result['STATION']:^12} | {cincinnati_result['NAME']:<50} | {cincinnati_result['Mean_PRCP']:.2f}\")\n",
        "print(f\"{florida_result['YEAR']:^6} | {florida_result['STATION']:^12} | {florida_result['NAME']:<50} | {florida_result['Mean_PRCP']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pTmygtn_dBx",
        "outputId": "b2b48468-d279-4842-b932-631889a71a2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Year with Most Precipitation for Cincinnati and Florida:\n",
            "\n",
            " Year  |    Station   |                 Station Name                       | Mean PRCP\n",
            "-------|--------------|----------------------------------------------------|----------\n",
            " 2024  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 5.44\n",
            " 2020  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 6\n",
        "# Count the percentage of missing values for wind gust (column GUST) for Cincinnati and Florida in the year 2024!\n",
        "\n",
        "# There should be 2 results.\n",
        "\n",
        "# Again, as usual, import the necessary libraries and modules.\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Again, define file paths for 2024 data for Cincinnati and Florida\n",
        "cincinnati_2024_file = \"./weather_data/2024_72429793812.csv\"\n",
        "florida_2024_file = \"./weather_data/2024_99495199999.csv\"\n",
        "\n",
        "# Let's load 2024 data for Cincinnati again\n",
        "cincinnati_2024_df = spark.read.option(\"header\", \"true\").csv(cincinnati_2024_file)\n",
        "florida_2024_df = spark.read.option(\"header\", \"true\").csv(florida_2024_file)\n",
        "\n",
        "# Count missing GUST values and total rows for Cincinnati file of 2024\n",
        "cincinnati_missing_count = cincinnati_2024_df.filter(col(\"GUST\") == 999.9).count()\n",
        "cincinnati_total_count = cincinnati_2024_df.count()\n",
        "cincinnati_missing_percentage = (cincinnati_missing_count / cincinnati_total_count) * 100\n",
        "\n",
        "# Count missing GUST values and total rows for Florida file of 2024\n",
        "florida_missing_count = florida_2024_df.filter(col(\"GUST\") == 999.9).count()\n",
        "florida_total_count = florida_2024_df.count()\n",
        "florida_missing_percentage = (florida_missing_count / florida_total_count) * 100\n",
        "\n",
        "# Display the results for QUESTION 6\n",
        "print(\"\\nPercentage of Missing Values for Wind Gust (column GUST) for Cincinnati and Florida in 2024:\\n\")\n",
        "print(f\"Cincinnati: {cincinnati_missing_percentage:.2f}%\")\n",
        "print(f\"Florida: {florida_missing_percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "E0kFQ4ylCwDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100d68e6-469a-4f02-b2f3-761fb6d03c75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Percentage of Missing Values for Wind Gust (column GUST) for Cincinnati and Florida in 2024:\n",
            "\n",
            "Cincinnati: 39.53%\n",
            "Florida: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 7\n",
        "# Find the mean, median, mode, and standard deviation of the temperature (column TEMP) for Cincinnati in each month for the year 2020.\n",
        "# There should be 12 results (one for each month, with 4 values for each result).\n",
        "\n",
        "# Here are the imported modules and libraries, again\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, month, mean, stddev, expr, count\n",
        "from pyspark.sql import Window\n",
        "\n",
        "# Define file path for Cincinnati 2020 data of the weather\n",
        "cincinnati_2020_file = \"./weather_data/2020_72429793812.csv\"\n",
        "\n",
        "# Load 2020 data for Cincinnati, now!\n",
        "cincinnati_2020_df = spark.read.option(\"header\", \"true\").csv(cincinnati_2020_file)\n",
        "\n",
        "# Convert TEMP to float now\n",
        "cincinnati_2020_df = cincinnati_2020_df.withColumn(\"TEMP\", col(\"TEMP\").cast(\"float\"))\n",
        "\n",
        "# Filter out rows with missing or placeholder values for TEMP, e.g., 9999.9\n",
        "cincinnati_2020_df = cincinnati_2020_df.filter((col(\"TEMP\") != 9999.9) & (col(\"TEMP\").isNotNull()))\n",
        "\n",
        "# Group data by month and calculate mean and standard deviation, EACH MONTH of 2020\n",
        "temp_stats_df = cincinnati_2020_df.withColumn(\"MONTH\", month(col(\"DATE\"))) \\\n",
        "    .groupBy(\"MONTH\") \\\n",
        "    .agg(\n",
        "        mean(\"TEMP\").alias(\"Mean_TEMP\"),\n",
        "        stddev(\"TEMP\").alias(\"StandardDeviation_TEMP\")\n",
        "    )\n",
        "\n",
        "# Calculate the median for each month of 2020\n",
        "temp_median_df = cincinnati_2020_df.withColumn(\"MONTH\", month(col(\"DATE\"))) \\\n",
        "    .groupBy(\"MONTH\") \\\n",
        "    .agg(expr(\"percentile_approx(TEMP, 0.5)\").alias(\"Median_TEMP\"))\n",
        "\n",
        "# Calculate the mode for each month of 2020\n",
        "window = Window.partitionBy(\"MONTH\")\n",
        "temp_mode_df = cincinnati_2020_df.withColumn(\"MONTH\", month(col(\"DATE\"))) \\\n",
        "    .groupBy(\"MONTH\", \"TEMP\") \\\n",
        "    .agg(count(\"TEMP\").alias(\"Frequency\")) \\\n",
        "    .withColumn(\"Max_Freq\", expr(\"max(Frequency) over (PARTITION BY MONTH)\")) \\\n",
        "    .filter(col(\"Frequency\") == col(\"Max_Freq\")) \\\n",
        "    .groupBy(\"MONTH\") \\\n",
        "    .agg(expr(\"first(TEMP)\").alias(\"Mode_TEMP\"))\n",
        "\n",
        "# Combine all statistics into a single DataFrame now\n",
        "final_stats_df = temp_stats_df \\\n",
        "    .join(temp_median_df, \"MONTH\") \\\n",
        "    .join(temp_mode_df, \"MONTH\") \\\n",
        "    .orderBy(\"MONTH\")\n",
        "\n",
        "# Display results in table format for the final answer\n",
        "print(\"\\nTemperature Statistics for Cincinnati for Each Month in 2020:\\n\")\n",
        "# Let's not truncate the values for better results (accurate)!\n",
        "final_stats_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6m2Y79ePdWX",
        "outputId": "92035254-63b0-4a5f-8773-e7f72b70f5e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Temperature Statistics for Cincinnati for Each Month in 2020:\n",
            "\n",
            "+-----+------------------+----------------------+-----------+---------+\n",
            "|MONTH|Mean_TEMP         |StandardDeviation_TEMP|Median_TEMP|Mode_TEMP|\n",
            "+-----+------------------+----------------------+-----------+---------+\n",
            "|1    |37.945161081129505|8.345810838316384     |37.7       |24.7     |\n",
            "|2    |36.58965525133856 |7.901597947537755     |36.0       |25.9     |\n",
            "|3    |49.0741934007214  |8.77940669347644      |47.8       |39.6     |\n",
            "|4    |51.77999992370606 |7.3131621276074465    |51.0       |49.4     |\n",
            "|5    |60.89032290058751 |9.314768319579512     |63.7       |73.9     |\n",
            "|6    |72.54666570027669 |4.8999458590264515    |73.7       |70.7     |\n",
            "|7    |77.6000001968876  |2.337947626620972     |77.9       |78.4     |\n",
            "|8    |73.34516143798828 |3.4878690606063563    |73.7       |78.3     |\n",
            "|9    |66.09999961853028 |7.118261579669542     |65.8       |74.5     |\n",
            "|10   |55.19354851015152 |6.7286914818367975    |54.0       |52.2     |\n",
            "|11   |48.00333340962728 |6.825938707865554     |47.7       |47.7     |\n",
            "|12   |35.99354830095845 |6.6427872766495755    |35.2       |32.1     |\n",
            "+-----+------------------+----------------------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 8\n",
        "# Find the top 10 days with the lowest Wind Chill for Cincinnati in 2017 (Points: 1):\n",
        "# For days where TEMP is below 50°F and WDSP (wind speed) is above 3 mph, calculate Wind Chill using the formula:\n",
        "# WC = 35.74 + 0.6215 × TEMP − 35.75 × (WDSP)^0.16 + 0.4275 × TEMP × (WDSP)^0.16\n",
        "# Add a new column for Wind Chill and display the top 10 days with the lowest Wind Chill.\n",
        "\n",
        "\n",
        "# Here are the necessary imports again...\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "# Defining the file path for Cincinnati (2017)\n",
        "cincinnati_2017_file = \"./weather_data/2017_72429793812.csv\"\n",
        "\n",
        "# Loading the 2017's data for Cincinnati\n",
        "cincinnati_2017_df = spark.read.option(\"header\", \"true\").csv(cincinnati_2017_file)\n",
        "\n",
        "# Convert TEMP and WDSP to float for calculations\n",
        "cincinnati_2017_df = cincinnati_2017_df.withColumn(\"TEMP\", col(\"TEMP\").cast(\"float\")) \\\n",
        "                                       .withColumn(\"WDSP\", col(\"WDSP\").cast(\"float\"))\n",
        "\n",
        "# Filtering for days where TEMP < 50°F and WDSP > 3 mph\n",
        "filtered_df = cincinnati_2017_df.filter((col(\"TEMP\") < 50) & (col(\"WDSP\") > 3))\n",
        "\n",
        "# Calculating Wind Chill using the given formula\n",
        "wind_chill_df = filtered_df.withColumn(\"Wind_Chill\",\n",
        "    (35.74 + (0.6215 * col(\"TEMP\")) - (35.75 * (col(\"WDSP\") ** 0.16))) + (0.4275 * col(\"TEMP\") * (col(\"WDSP\") ** 0.16))\n",
        ")\n",
        "\n",
        "# Now, finally, let's select and display the top 10 days with the lowest Wind Chill\n",
        "top_10_lowest_wc = wind_chill_df.orderBy(col(\"Wind_Chill\").asc()).select(\"NAME\", \"DATE\", \"TEMP\", \"WDSP\", \"Wind_Chill\").limit(10)\n",
        "\n",
        "# Finally, let's show the results/answer of this question\n",
        "print(\"\\nTop 10 Days with the Lowest Wind Chill for Cincinnati in 2017:\\n\")\n",
        "# Let's not truncate the values for better results (accurate)!\n",
        "top_10_lowest_wc.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r73W4deYfpI0",
        "outputId": "b7e4a7b0-c394-42a6-c72a-6c194614f34d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Days with the Lowest Wind Chill for Cincinnati in 2017:\n",
            "\n",
            "+------------------------------------------------+----------+----+----+-------------------+\n",
            "|NAME                                            |DATE      |TEMP|WDSP|Wind_Chill         |\n",
            "+------------------------------------------------+----------+----+----+-------------------+\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-01-07|10.5|7.0 |-0.4140156367932173|\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-31|11.0|5.3 |2.0339764741541018 |\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-27|13.0|5.8 |3.8206452986638073 |\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-28|13.6|5.8 |4.533355513517824  |\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-01-06|13.6|5.5 |4.868933492954463  |\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-01-08|15.9|5.2 |7.929747979856229  |\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-25|25.8|13.5|14.285112249501509 |\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-30|21.6|5.3 |14.539211503699956 |\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-01-05|22.2|5.8 |14.748862551376547 |\n",
            "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-26|23.3|6.2 |15.688977064714743 |\n",
            "+------------------------------------------------+----------+----+----+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 9 (for just the year of 2024)\n",
        "# Investigate how many days in 2024 had extreme weather conditions for Florida (fog, rain, snow, etc.) using the FRSHTT column (Points: 1).\n",
        "# There should be 1 result.\n",
        "\n",
        "# FRSHTT - Indicators (1 = yes, 0 = no/not reported) for the occurrence during the day of:\n",
        "    # Fog ('F' - 1st digit).\n",
        "    # Rain or Drizzle ('R' - 2nd digit).\n",
        "    # Snow or Ice Pellets ('S' - 3rd digit).\n",
        "    # Hail ('H' - 4th digit).\n",
        "    # Thunder ('T' - 5th digit).\n",
        "    # Tornado or Funnel Cloud ('T' - 6th digit).\n",
        "\n",
        "# Here are the necessary imports, again\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Defining file path for Florida data for 2024\n",
        "florida_file = \"./weather_data/2024_99495199999.csv\"  # Replace with the file path as needed, I am choosing Florida\n",
        "\n",
        "# There are 158 days for Cincinnati in 2024, and I get the same result (I have Tested it as well)\n",
        "# Cincinnati for 2024 (please ignore the \"file name\" variable, file path is for Cincinnati 2024)\n",
        "# florida_file = \"./weather_data/2024_72429793812.csv\"  # Replace with the file path as needed, I am choosing Florida\n",
        "\n",
        "# Loading the data for Florida of 2024\n",
        "florida_df = spark.read.option(\"header\", \"true\").csv(florida_file)\n",
        "\n",
        "# Filtering for extreme weather days where any FRSHTT indicator is 1 (Yes) as stated in the README.pdf\n",
        "extreme_weather_df = florida_df.filter(\n",
        "    (col(\"FRSHTT\").substr(1, 1) == \"1\") |  # Fog\n",
        "    (col(\"FRSHTT\").substr(2, 1) == \"1\") |  # Rain or Drizzle\n",
        "    (col(\"FRSHTT\").substr(3, 1) == \"1\") |  # Snow or Ice Pellets\n",
        "    (col(\"FRSHTT\").substr(4, 1) == \"1\") |  # Hail\n",
        "    (col(\"FRSHTT\").substr(5, 1) == \"1\") |  # Thunder\n",
        "    (col(\"FRSHTT\").substr(6, 1) == \"1\")    # Tornado or Funnel Cloud\n",
        ")\n",
        "\n",
        "# Counting the number of extreme weather days in Florida for 2024\n",
        "extreme_weather_days_count = extreme_weather_df.count()\n",
        "\n",
        "# Finally, let's display the results now\n",
        "print(f\"\\nNumber of Days with Extreme Weather Conditions in Florida in 2024: {extreme_weather_days_count}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk5Kx28jiFrx",
        "outputId": "d7f403f3-5a00-4ba9-f924-feba843c4e13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Days with Extreme Weather Conditions in Florida in 2024: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 9 (for years from 2015-2024) -- continued\n",
        "# Investigate how many days from 2015-2024 had extreme weather conditions for Florida (fog, rain, snow, etc.) using the FRSHTT column (Points: 1).\n",
        "# There should be 1 result.\n",
        "\n",
        "# FRSHTT - Indicators (1 = yes, 0 = no/not reported) for the occurrence during the day of:\n",
        "    # Fog ('F' - 1st digit).\n",
        "    # Rain or Drizzle ('R' - 2nd digit).\n",
        "    # Snow or Ice Pellets ('S' - 3rd digit).\n",
        "    # Hail ('H' - 4th digit).\n",
        "    # Thunder ('T' - 5th digit).\n",
        "    # Tornado or Funnel Cloud ('T' - 6th digit).\n",
        "\n",
        "# Here are the necessary imports, again\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Again, define the base directory and years for Florida files\n",
        "data_directory = \"./weather_data\"\n",
        "years = [y for y in range(2015, 2025) if y != 2016]  # Skip 2016 if file does not exist\n",
        "\n",
        "# Let's list to store DataFrames for each year, it's empty, initially\n",
        "florida_dfs = []\n",
        "\n",
        "# Loading data for each year and append to the list - only FLORIDA\n",
        "for year in years:\n",
        "    florida_file = f\"{data_directory}/{year}_99495199999.csv\"\n",
        "    florida_df = spark.read.option(\"header\", \"true\").csv(florida_file)\n",
        "    florida_dfs.append(florida_df)\n",
        "\n",
        "# ==================================================================================================================\n",
        "# ==================================================================================================================\n",
        "\n",
        "# # For Cincinnati, please execute this \"for\" loop and make sure to comment-out the \"for\" loop written above.\n",
        "# # Ignore the variable names, because the file path is of Cincinnati\n",
        "\n",
        "# for year in years:\n",
        "#     florida_file = f\"{data_directory}/{year}_72429793812.csv\"\n",
        "#     florida_df = spark.read.option(\"header\", \"true\").csv(florida_file)\n",
        "#     florida_dfs.append(florida_df)\n",
        "\n",
        "# ==================================================================================================================\n",
        "# ==================================================================================================================\n",
        "\n",
        "# Union/Combine all DataFrames for Florida from 2015 to 2024\n",
        "all_florida_df = florida_dfs[0]\n",
        "for df in florida_dfs[1:]:\n",
        "    all_florida_df = all_florida_df.union(df)\n",
        "\n",
        "# Convert FRSHTT to string for substring operations\n",
        "all_florida_df = all_florida_df.withColumn(\"FRSHTT\", col(\"FRSHTT\").cast(\"string\"))\n",
        "\n",
        "# Filter for extreme weather days where any FRSHTT indicator is 1\n",
        "extreme_weather_df = all_florida_df.filter(\n",
        "    (col(\"FRSHTT\").substr(1, 1) == \"1\") |  # Fog\n",
        "    (col(\"FRSHTT\").substr(2, 1) == \"1\") |  # Rain or Drizzle\n",
        "    (col(\"FRSHTT\").substr(3, 1) == \"1\") |  # Snow or Ice Pellets\n",
        "    (col(\"FRSHTT\").substr(4, 1) == \"1\") |  # Hail\n",
        "    (col(\"FRSHTT\").substr(5, 1) == \"1\") |  # Thunder\n",
        "    (col(\"FRSHTT\").substr(6, 1) == \"1\")    # Tornado/Funnel Cloud\n",
        ")\n",
        "\n",
        "# Count the number of extreme weather days for the years ranging from 2015-2024\n",
        "extreme_weather_days_count = extreme_weather_df.count()\n",
        "\n",
        "# Finally, let's display the results now\n",
        "print(f\"\\nNumber of Days with Extreme Weather Conditions in Florida for all years from 2015 to 2024: {extreme_weather_days_count}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6faTDP-Qmar0",
        "outputId": "eec158c7-df4d-448e-af8b-abe4c3f33a9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Days with Extreme Weather Conditions in Florida for all years from 2015 to 2024: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 10\n",
        "# Predict the maximum Temperature for Cincinnati for November and December 2024, based on the previous 2 years of weather data (Points: 1):\n",
        "# There should be 2 results.\n",
        "# You can use any model  to forecast on the historical weather data.\n",
        "\n",
        "# Here are the necessary imports\n",
        "from pyspark.sql.functions import col, avg, month, max, year\n",
        "\n",
        "# Filtering the data for 2022 and 2023 and remove invalid MAX values\n",
        "cincinnati_2022_2023 = cincinnati_df.filter((year(col(\"DATE\")).isin([2022, 2023])) & (col(\"MAX\") != 9999.9))\n",
        "\n",
        "# Calculating the max temperature for November in 2022 and 2023 in Cincinnati\n",
        "# 2022 NOVEMBER\n",
        "nov_max_temp_2022 = cincinnati_2022_2023.filter((year(col(\"DATE\")) == 2022) & (month(col(\"DATE\")) == 11)) \\\n",
        "    .agg(max(\"MAX\").alias(\"Max_Nov_2022\")) \\\n",
        "    .collect()[0][\"Max_Nov_2022\"]\n",
        "\n",
        "# 2023 NOVEMBER\n",
        "nov_max_temp_2023 = cincinnati_2022_2023.filter((year(col(\"DATE\")) == 2023) & (month(col(\"DATE\")) == 11)) \\\n",
        "    .agg(max(\"MAX\").alias(\"Max_Nov_2023\")) \\\n",
        "    .collect()[0][\"Max_Nov_2023\"]\n",
        "\n",
        "# Now, 2022 DECEMBER\n",
        "dec_2022_all_temps = cincinnati_2022_2023.filter((year(col(\"DATE\")) == 2022) & (month(col(\"DATE\")) == 12)) \\\n",
        "    .orderBy(col(\"MAX\").desc())\n",
        "\n",
        "# Convert results to a list and get the highest values, ignoring the missing data which has a value of 9999.9\n",
        "dec_2022_max_values = [row[\"MAX\"] for row in dec_2022_all_temps.collect() if row[\"MAX\"] != 9999.9]\n",
        "\n",
        "if len(dec_2022_max_values) >= 2:\n",
        "    dec_max_temp_2022 = dec_2022_max_values[1]  # Highest Temperature Value\n",
        "elif len(dec_2022_max_values) == 1:\n",
        "    dec_max_temp_2022 = dec_2022_max_values[0]  # Only 1 Value\n",
        "else:\n",
        "    dec_max_temp_2022 = None  # No valid values found\n",
        "\n",
        "# Let's calculate the MAX temperature for December 2023\n",
        "dec_max_temp_2023 = cincinnati_2022_2023.filter((year(col(\"DATE\")) == 2023) & (month(col(\"DATE\")) == 12)) \\\n",
        "    .agg(max(\"MAX\").alias(\"Max_Dec_2023\")) \\\n",
        "    .collect()[0][\"Max_Dec_2023\"]\n",
        "\n",
        "# Now, calculating the averages of 2022 and 2023 for predicting the temperatures in November 2024 and December 2024\n",
        "nov_avg_max_temp = (float(nov_max_temp_2022) + float(nov_max_temp_2023)) / 2\n",
        "dec_avg_max_temp = (float(dec_max_temp_2022) + float(dec_max_temp_2023)) / 2 if dec_max_temp_2022 is not None else None\n",
        "\n",
        "# Finally, let's display the max temps for 2022 and 2023, and the predictions for 2024\n",
        "print(f\"Cincinnati's Maximum Temperature for November 2022                                     : {float(nov_max_temp_2022):.2f}°F\")\n",
        "print(f\"Cincinnati's Maximum Temperature for November 2023                                     : {float(nov_max_temp_2023):.2f}°F\")\n",
        "print(f\"Cincinnati's Predicted Maximum Temperature for November 2024                           : {float(nov_avg_max_temp):.2f}°F\\n\")\n",
        "\n",
        "if dec_max_temp_2022 is not None:\n",
        "    print(f\"Highest Maximum Temperature for December 2022 (ignoring the MISSING VALUES=9999.9)     : {float(dec_max_temp_2022):.2f}°F\")\n",
        "else:\n",
        "    print(\"No Valid Maximum Temperature found for December 2022.\")\n",
        "\n",
        "print(f\"Cincinnati's Maximum Temperature for December 2023                                     : {float(dec_max_temp_2023):.2f}°F\")\n",
        "if dec_avg_max_temp is not None:\n",
        "    print(f\"Cincinnati's Predicted Maximum Temperature for December 2024                           : {float(dec_avg_max_temp):.2f}°F\")\n",
        "else:\n",
        "    print(\"Cannot Calculate Predicted Max Temperature for December 2024 due to Missing Valid Data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg05LXiIpDP1",
        "outputId": "c8ae8824-9b9e-447f-ae49-20cdb31ce023"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cincinnati's Maximum Temperature for November 2022                                     : 75.90°F\n",
            "Cincinnati's Maximum Temperature for November 2023                                     : 80.10°F\n",
            "Cincinnati's Predicted Maximum Temperature for November 2024                           : 78.00°F\n",
            "\n",
            "Highest Maximum Temperature for December 2022 (ignoring the MISSING VALUES=9999.9)     : 66.00°F\n",
            "Cincinnati's Maximum Temperature for December 2023                                     : 64.00°F\n",
            "Cincinnati's Predicted Maximum Temperature for December 2024                           : 65.00°F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 10 (Brief Discussion on the model’s performance and potential improvements)\n",
        "\n",
        "#   In my approach, I focused on predicting Cincinnati's maximum temperatures for November and December 2024 by looking at data\n",
        "# from the previous two years (i.e., 2022's and 2023's November and December). I filtered out erroneous values, specifically those\n",
        "# marked as 9999.9, which often indicate missing data, and then calculated the average of the highest valid temperatures from each\n",
        "# month to estimate the 2024's Maximum Temperatures for the month of November and December in Cincinnati.\n",
        "#   Now, one might be wondering - \"Why I decided/chose to ignore those missing values?\", this is because, 9999.9 value(s) represent\n",
        "# missing or invalid data and including them could have skewed the results. Replacing them with a mean/average temperature of that particular\n",
        "# month of that specific year would artificially alter the dataset and could misrepresent extreme temperature trends, so skipping these values\n",
        "# gives a more accurate prediction.\n",
        "#   In my opinion, this averaging method provides a reasonable estimate, but it doesn’t capture yearly trends or account for other possible\n",
        "# influences like humidity or precipitation. Here’s how I think the model could be improved in future, if needed:\n",
        "#       1. Exploring a Time-Series Model (like ARIMA, Prophet or LSTM, etc.): These Deep Learning architectures/models are designed to handle seasonal\n",
        "#                                                                             variations, which would likely make the predictions more accurate. I would\n",
        "#                                                                             use Mean Square Error (MSE) as my Loss Function because the data is of\n",
        "#                                                                             \"Regression\" type and not \"Classification\" type.\n",
        "#       2. Incorporating Additional Weather Features: Including other factors could better capture the dependencies that affect maximum temperatures.\n",
        "\n",
        "# Finally, in summary, I can definitely say that the current approach works as a quick estimation for predicting the Maximum Temperature for Cincinnati (accurately) for\n",
        "# November and December 2024, based on the previous 2 years of weather data (i.e., 2022 and 2023), using a time-series model would likely give me a better, more nuanced\n",
        "# prediction by recognizing patterns in the data."
      ],
      "metadata": {
        "id": "7j2_9bEX38Lj"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}